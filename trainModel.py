import torch.optim as optim
from torch.utils.data import DataLoader, Dataset

# Imagine you have a custom dataset that returns (image1, image2, label)
class DualCameraDataset(Dataset):
    def __init__(self, data_list, transform):
        self.data_list = data_list  # List of tuples: (path_cam1, path_cam2, label)
        self.transform = transform

    def __len__(self):
        return len(self.data_list)

    def __getitem__(self, idx):
        path1, path2, label = self.data_list[idx]
        # Load images using PIL
        img1 = Image.open(path1).convert("RGB")
        img2 = Image.open(path2).convert("RGB")
        img1 = self.transform(img1)
        img2 = self.transform(img2)
        return img1, img2, label

# Suppose 'data_list' is prepared from your collected data
# data_list = [("cam1_img1.jpg", "cam2_img1.jpg", 0), ("cam1_img2.jpg", "cam2_img2.jpg", 1), ...]
dataset = DualCameraDataset(data_list=[], transform=transform)
dataloader = DataLoader(dataset, batch_size=16, shuffle=True)

# Set up loss and optimizer
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

# Training loop
model.train()
num_epochs = 20  # You might need more epochs for better accuracy

for epoch in range(num_epochs):
    running_loss = 0.0
    for imgs1, imgs2, labels in dataloader:
        optimizer.zero_grad()
        outputs = model(imgs1, imgs2)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        running_loss += loss.item()
    print(f"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(dataloader):.4f}")

print("Training complete!")
